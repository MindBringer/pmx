# Server
RAG_BIND=0.0.0.0
RAG_PORT=8082
SCORE_THRESHOLD=0.3   # 0 = aus, z.B. 0.2–0.4 ist oft gut

# Qdrant (must be reachable on pmx-net)
QDRANT_URL=http://qdrant:6333
QDRANT_COLLECTION=pmx_docs
QDRANT_TIMEOUT=30

# Ollama (service name from pmx stack)
OLLAMA_BASE_URL=http://ollama:11434

# Models (swappable)
LLM_MODEL=llama3
GENERATOR_MODEL=llama3
EMBED_MODEL=mxbai-embed-large

# Chunking
CHUNK_SIZE=1200
CHUNK_OVERLAP=120

# Security
API_KEY=change-me
ALLOWED_ORIGINS=*
ENABLE_RERANKER=false
RERANK_MODEL=bge-reranker-v2-m3

# Audio
WHISPER_MODEL=small            # z.B. small | medium | large-v3
WHISPER_DEVICE=cpu             # oder cuda (falls GPU)
WHISPER_COMPUTE_TYPE=int8      # z.B. int8 | int8_float16 | float16
WHISPER_CACHE=/app/storage/whisper

#diarization / speaker rec.
DEVICE=cpu                # später: cuda
ASR_ENGINE=faster-whisper
ASR_MODEL=medium          # tiny/base/small/medium/large-v3 etc.
ASR_COMPUTE_TYPE=int8     # cpu: int8 | gpu: float16
DIAR_ENGINE=local         # local | pyannote | nemo (Hooks vorbereitet)
DIAR_MAX_SPEAKERS=0       # 0 = auto (online clustering), sonst feste Zahl
IDENTIFICATION=true       # optional Personenerkennung
SPEAKER_STORE=qdrant      # file | qdrant (Adapter vorbereitet; default: qdrant)