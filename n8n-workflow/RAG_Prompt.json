{
  "name": "RAG_Prompt",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "llm",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "445d8cb6-168e-4285-b652-d4a78ee64c92",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 2,
      "position": [
        -1888,
        676
      ],
      "webhookId": "llm-router"
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "model-assignment",
              "name": "model",
              "value": "={{ $json.body.model || $json.model }}",
              "type": "string"
            },
            {
              "id": "prompt-assignment",
              "name": "prompt",
              "value": "={{ $json.body.prompt || $json.prompt }}",
              "type": "string"
            },
            {
              "id": "system-assignment",
              "name": "system",
              "value": "={{ $json.body.system || $json.system || '' }}",
              "type": "string"
            },
            {
              "id": "6fbc415f-9e43-4139-b904-75eaad8fbaf6",
              "name": "rag",
              "value": "={{ $json.body.rag || $json.rag }}",
              "type": "string"
            },
            {
              "id": "3903d1e7-8b4d-4211-8cd2-f27783117e7c",
              "name": "rag_top_k",
              "value": "={{ $json.body.rag_top_k || 5 }}",
              "type": "string"
            },
            {
              "id": "d231f6ca-e78a-4412-be6d-3545b4599f4e",
              "name": "rag_score_threshold",
              "value": "={{ $json.body.rag_score_threshold || 0.45 }}",
              "type": "string"
            },
            {
              "id": "10392c3e-b687-40d2-9ea1-81d708b137f3",
              "name": "rag_api_key",
              "value": "={{ $json.body.rag_api_key || $env.RAG_API_KEY || 'change-me' }}",
              "type": "string"
            },
            {
              "id": "1e8e7b46-9ec5-49f7-9330-47988330f09d",
              "name": "rag_tags",
              "value": "={{ $json.body.rag_tags || [] }}",
              "type": "string"
            },
            {
              "id": "hf-model-assignment",
              "name": "hf_model",
              "value": "={{ $json.body.hf_model || $json.hf_model || 'microsoft/DialoGPT-medium' }}",
              "type": "string"
            },
            {
              "id": "openai-model-assignment",
              "name": "openai_model",
              "value": "={{ $json.body.openai_model || $json.openai_model || 'gpt-4o-mini' }}",
              "type": "string"
            },
            {
              "id": "claude-model-assignment",
              "name": "claude_model",
              "value": "={{ $json.body.claude_model || $json.claude_model || 'claude-3-5-sonnet-20240620' }}",
              "type": "string"
            },
            {
              "id": "ollama-model-assignment",
              "name": "ollama_model",
              "value": "={{ $json.body.ollama_model || $json.ollama_model || $json.model || 'llama3' }}",
              "type": "string"
            },
            {
              "id": "0b66fc63-ad7f-4b97-a509-bd783b11d785",
              "name": "mistral_model",
              "value": "={{ $json.body.mistral_model || $json.mistral_model || 'codestral-2501' }}",
              "type": "string"
            }
          ]
        },
        "options": {}
      },
      "id": "1565922b-0389-48a7-b723-038d3787f599",
      "name": "Extract Fields",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -1664,
        676
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "openai-condition",
              "leftValue": "={{ $json.rag }}",
              "rightValue": "false",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "1eaf501a-1364-45f9-b81d-ade04d367b60",
      "name": "without rag?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -1440,
        676
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://rag-backend:8082/query",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "x-api-key",
              "value": "={{ $('Extract Fields').item.json.rag_api_key }}"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  query: $('Extract Fields').item.json.prompt,\n  top_k: Number($('Extract Fields').item.json.rag_top_k) || 5,\n  score_threshold: Number($('Extract Fields').item.json.rag_score_threshold) || 0.45,\n  tags: Array.isArray($('Extract Fields').item.json.rag_tags) ? $('Extract Fields').item.json.rag_tags : []\n}) }}",
        "options": {
          "timeout": 300000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1216,
        748
      ],
      "id": "4411db0a-0640-453c-bfb8-94120087de18",
      "name": "RAG Query"
    },
    {
      "parameters": {
        "jsCode": "// Eingaben\nconst inData = $input.first().json || {};\nconst base   = $('Extract Fields').first().json || {};\n\n// Quellen hÃ¼bsch formatieren (max 8)\nconst sources = Array.isArray(inData.sources) ? inData.sources : [];\nconst lines = sources.slice(0, 8).map((s, i) => {\n  const fn    = s?.meta?.filename || s?.filename || `Quelle ${i+1}`;\n  const score = (typeof s?.score === 'number') ? ` (score: ${s.score.toFixed(3)})` : '';\n  const snip  = s?.snippet ?? s?.content ?? s?.meta?.text ?? '';\n  const short = String(snip).replace(/\\s+/g, ' ').trim().slice(0, 600);\n  return `- ${fn}${score}: ${short}`;\n});\n\nconst contextBlock = lines.length ? `Kontext aus Firmendaten:\\n${lines.join('\\n')}\\n\\n` : '';\nconst systemBlock  = (base.system && String(base.system).trim()) ? String(base.system).trim() + '\\n\\n' : '';\nconst userPrompt   = String(base.prompt ?? '').trim();\nconst augmented    = `${systemBlock}${contextBlock}Frage: ${userPrompt}`;\n\nconst modelOllama = base.ollama_model || base.model || 'llama3';\nconst temperature = typeof base.temperature === 'number' ? base.temperature : 0.7;\nconst top_p       = typeof base.top_p === 'number' ? base.top_p : 0.9;\nconst num_predict = typeof base.num_predict === 'number' ? base.num_predict : 600;\n\nconst ollama_body_json = JSON.stringify({\n  model: modelOllama,\n  prompt: augmented,\n  stream: false,\n  options: { temperature, top_p, num_predict }\n});\n\nreturn {\n  prompt: augmented,\n  system: base.system || '',\n  model: base.model,\n  ollama_model: modelOllama,\n  hf_model: base.hf_model,\n  openai_model: base.openai_model,\n  claude_model: base.claude_model,\n  mistral_model: base.mistral_model,\n  temperature, top_p, num_predict,\n  ollama_body_json,\n  augmented_prompt: augmented,\n  sources,\n  used_tags: inData.used_tags || [],\n  rag_suggested_answer: inData.answer || null\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -992,
        748
      ],
      "id": "a55012c7-05e0-4caa-bb82-6cc3f38574db",
      "name": "Build Augmented Prompt"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "openai-condition",
              "leftValue": "={{ $json.model }}",
              "rightValue": "groq",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "ec28e7ce-363b-4b68-afdf-3a28ca5a62ff",
      "name": "Is groq?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -768,
        676
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "openai-condition",
              "leftValue": "={{ $json.model }}",
              "rightValue": "openrouter",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "7750eb51-bdc9-4fba-988a-c3e9f62b599c",
      "name": "Is openrouter?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -544,
        876
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "openai-condition",
              "leftValue": "={{ $json.model }}",
              "rightValue": "mistralapi",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "7827befc-50a8-4e89-9efc-4ac57ec8ee89",
      "name": "Is mistralAPI?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -320,
        1024
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "openai-condition",
              "leftValue": "={{ $json.model }}",
              "rightValue": "openai",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "10c24a45-678c-403d-8260-758bda9161d0",
      "name": "Is OpenAI?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -96,
        1120
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "claude-condition",
              "leftValue": "={{ $json.model }}",
              "rightValue": "anthropic",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "3dab13c7-6ab2-4230-b2d7-eae530a2a8b1",
      "name": "Is Anthropic?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        128,
        1216
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "hf-condition",
              "leftValue": "={{ $json.model }}",
              "rightValue": "huggingface",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "4fa7be64-3b1c-4429-ab3d-28ac531b41c1",
      "name": "Is HuggingFace?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        352,
        1312
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "llama3-condition",
              "leftValue": "={{ $json.model }}",
              "rightValue": "mistral",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "5373d579-4180-429a-b58b-942a4fe7ddd7",
      "name": "Is Mistral?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        576,
        1408
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: $json.openai_model,\n  messages: [\n    ...(($json.system && $json.system.trim()) ? [{ role: 'system', content: $json.system }] : []),\n    { role: 'user', content: $json.prompt }\n  ],\n  max_tokens: 1000,\n  temperature: 0.7\n}) }}",
        "options": {}
      },
      "id": "00873854-43fa-4fdc-8b42-815e5d905c41",
      "name": "Call OpenAI",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        864,
        736
      ],
      "credentials": {
        "openAiApi": {
          "id": "xpFTPLasPN9qcrAU",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: $json.claude_model,\n  max_tokens: 1000,\n  messages: [{ role: 'user', content: $json.prompt }],\n  ...(($json.system && $json.system.trim()) ? { system: $json.system } : {})\n}) }}",
        "options": {}
      },
      "id": "c291b2b8-e787-4e5c-ba4f-6744357fcc44",
      "name": "Call Claude",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        864,
        928
      ],
      "credentials": {
        "anthropicApi": {
          "id": "NwPymGLQdk29P5fi",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api-inference.huggingface.co/models/{{ $json.hf_model }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "huggingFaceApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  inputs: ($json.system && $json.system.trim()) ? ($json.system + '\\n\\n' + $json.prompt) : $json.prompt,\n  parameters: { max_length: 500, temperature: 0.7, do_sample: true, return_full_text: False }\n}) }}",
        "options": {}
      },
      "id": "4e4a9ce1-1e38-4ae7-b483-0955c4885aa7",
      "name": "Call Hugging Face",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        864,
        1120
      ],
      "credentials": {
        "huggingFaceApi": {
          "id": "QO87qgUFRrbiQqXv",
          "name": "HuggingFaceApi account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.mistral.ai/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "mistralCloudApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: $json.mistral_model,\n  messages: [\n    { role: 'system', content: ($json.system || 'Du bist ein hilfsbereiter Assistent.') },\n    { role: 'user', content: $json.prompt }\n  ],\n  max_tokens: 200,\n  temperature: 0.7\n}) }}",
        "options": {}
      },
      "id": "6af58ba9-1ce4-40c2-b9e9-2b0496d6b0aa",
      "name": "Call mistralAPI",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        864,
        544
      ],
      "credentials": {
        "mistralCloudApi": {
          "id": "cp078sOI6OYLKqiI",
          "name": "Mistral Cloud API-key"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://ollama:11434/api/generate",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: ($json.ollama_model) ?? ($('Extract Fields').item.json.ollama_model ?? $('Extract Fields').item.json.model ?? 'llama3'),\n  prompt: ($json.prompt) ?? ($('Extract Fields').item.json.prompt ?? ''),\n  stream: false,\n  options: {\n    temperature: (typeof $json.temperature === 'number') ? $json.temperature : (typeof $('Extract Fields').item.json.temperature === 'number' ? $('Extract Fields').item.json.temperature : 0.7),\n    top_p:       (typeof $json.top_p === 'number')       ? $json.top_p       : (typeof $('Extract Fields').item.json.top_p === 'number'       ? $('Extract Fields').item.json.top_p       : 0.9),\n    num_predict: (typeof $json.num_predict === 'number') ? $json.num_predict : (typeof $('Extract Fields').item.json.num_predict === 'number' ? $('Extract Fields').item.json.num_predict : 600)\n  }\n}) }}",
        "options": {
          "timeout": 300000
        }
      },
      "id": "ca77e4b6-846d-4c91-a0da-b6cc3e3e7ecd",
      "name": "Call Ollama",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        864,
        1312
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://ollama:11434/api/generate",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: 'llama3',\n  prompt: ($json.system && $json.system.trim()) ? ($json.system + '\\n\\n' + $json.prompt) : $json.prompt,\n  stream: false,\n  options: { temperature: 0.7, num_predict: 500 }\n}) }}",
        "options": {}
      },
      "id": "bbd9f1ae-557d-4fee-a941-082baddbf3fe",
      "name": "Call Llama (Default)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        864,
        1504
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.system ? $json.system + \"\\n\\n\" + $json.prompt : $json.prompt }}\n",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        800,
        144
      ],
      "id": "a92159bc-d4f6-4988-b5d8-d6d66749bb1f",
      "name": "Basic LLM Chain"
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        808,
        368
      ],
      "id": "fc12f589-2270-4a73-86cf-8e04c36aac22",
      "name": "OpenRouter Chat Model",
      "credentials": {
        "openRouterApi": {
          "id": "h5qqZ7le0CZSkkCh",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "model": "qwen/qwen3-32b",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        936,
        368
      ],
      "id": "42382ae3-d17e-427c-bb50-e5069a95c54c",
      "name": "Groq Chat Model1",
      "credentials": {
        "groqApi": {
          "id": "mhumLW1ZXnpB1MfM",
          "name": "Groq account"
        }
      }
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.system ? $json.system + \"\\n\\n\" + $json.prompt : $json.prompt }}\n",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        800,
        -256
      ],
      "id": "e8a0c86c-46e8-4f7a-86a9-80b7e39551d0",
      "name": "Basic LLM Chain1"
    },
    {
      "parameters": {
        "model": "moonshotai/kimi-k2-instruct",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        808,
        -32
      ],
      "id": "415fc2d0-781a-4bc5-b8a6-e5351bf6e88c",
      "name": "Groq Chat Model",
      "credentials": {
        "groqApi": {
          "id": "mhumLW1ZXnpB1MfM",
          "name": "Groq account"
        }
      }
    },
    {
      "parameters": {
        "model": "deepseek-r1-distill-llama-70b",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        936,
        -32
      ],
      "id": "3abc6a01-67ec-4001-8993-8a3b495649c6",
      "name": "Groq Chat Model2",
      "credentials": {
        "groqApi": {
          "id": "mhumLW1ZXnpB1MfM",
          "name": "Groq account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Robust response formatter across providers (NDJSON + SSE streaming aware)\nconst requested = $('Extract Fields').first().json || {};\nconst item = $input.first();\nconst data = item.json;\n\n// --- Helpers ---\n\n// Parse NDJSON (newline-delimited JSON), used by Ollama and some proxies\nfunction parseNdjsonString(s) {\n  try {\n    const lines = String(s).trim().split('\\n').filter(Boolean);\n    const objects = lines.map(l => JSON.parse(l));\n    return objects;\n  } catch {\n    return null;\n  }\n}\n\n// Parse SSE-like 'data: {...}\\n\\n' streams (OpenRouter/Groq/OpenAI-style)\nfunction parseSseString(s) {\n  const out = [];\n  const lines = String(s).split('\\n');\n  for (const line of lines) {\n    const trimmed = line.trim();\n    if (!trimmed) continue;\n    if (!trimmed.toLowerCase().startsWith('data:')) continue;\n    const payload = trimmed.slice(5).trim();\n    if (!payload || payload === '[DONE]') continue;\n    try { out.push(JSON.parse(payload)); } catch {}\n  }\n  return out.length ? out : null;\n}\n\n// Extract text content from a variety of chunk shapes\nfunction extractTextFromChunk(obj) {\n  // Ollama\n  if (typeof obj.response === 'string') return obj.response;\n\n  // OpenAI-like deltas\n  const choice0 = obj.choices && obj.choices[0];\n  if (choice0) {\n    if (choice0.delta && typeof choice0.delta.content === 'string') return choice0.delta.content;\n    if (choice0.message && typeof choice0.message.content === 'string') return choice0.message.content;\n    if (typeof choice0.text === 'string') return choice0.text;\n    if (Array.isArray(choice0.content)) {\n      return choice0.content.map(c => (typeof c.text === 'string' ? c.text : '')).join('');\n    }\n  }\n\n  // OpenRouter-style tokens\n  if (typeof obj.content === 'string') return obj.content;\n  if (typeof obj.output_text === 'string') return obj.output_text;\n  if (typeof obj.text === 'string') return obj.text;\n\n  return '';\n}\n\n// --- Main ---\n\nlet result, provider, actualModel, usage = null, raw = data;\n\n// 1) If body came as string, try NDJSON and then SSE\nif (data && typeof data.data === 'string') {\n  // Try NDJSON first (Ollama)\n  let chunks = parseNdjsonString(data.data);\n  if (chunks && chunks.length) {\n    provider = 'Ollama';\n    actualModel = (chunks.find(o => o.done === true)?.model) || chunks[0]?.model || requested.ollama_model;\n    const textParts = chunks.map(extractTextFromChunk).filter(Boolean);\n    result = textParts.join('').trim();\n    raw = { ndjson: chunks };\n  } else {\n    // Try SSE (OpenRouter/Groq-style)\n    chunks = parseSseString(data.data);\n    if (chunks && chunks.length) {\n      provider = (chunks.find(o => o?.provider) ? 'OpenRouter' : 'Groq/OpenAI-like');\n      actualModel = (chunks.find(o => o?.model)?.model) || requested.model || requested.openai_model || requested.ollama_model;\n      const textParts = chunks.map(extractTextFromChunk).filter(Boolean);\n      result = textParts.join('').trim();\n      raw = { sse: chunks };\n    }\n  }\n}\n\n// 2) Non-streaming structured responses\nif (!result) {\n  if (data && data.choices?.[0]?.message) {\n    result = data.choices[0].message.content; provider='OpenAI'; actualModel=data.model||requested.openai_model;\n    usage = data.usage || null;\n  } else if (data && Array.isArray(data.content) && data.content[0]) {\n    result = data.content[0].text || data.content[0].content; provider='Claude/Anthropic'; actualModel=data.model||requested.claude_model;\n  } else if (Array.isArray(data) && data[0]?.generated_text) {\n    result = data[0].generated_text; provider='Hugging Face'; actualModel=requested.hf_model;\n  } else if (data && data.generated_text) {\n    result = data.generated_text; provider='Hugging Face'; actualModel=requested.hf_model;\n  } else if (data && typeof data.response === 'string') {\n    result = data.response; provider='Ollama'; actualModel=data.model||requested.ollama_model;\n  } else if (data && data.text) {\n    result = data.text; provider='OpenRouter'; actualModel=requested.model || requested.openai_model || requested.ollama_model;\n  } else if (data && data.error) {\n    result = `Error: ${data.error.message || JSON.stringify(data.error)}`; provider='Error'; actualModel='N/A';\n  } else {\n    result = `Unexpected response format: ${JSON.stringify(data)}`; provider='Unknown'; actualModel='N/A';\n  }\n}\n\n// 3) RAG-Metadaten anhÃ¤ngen\nconst ragNode = $('Build Augmented Prompt');\nlet sources = [];\nlet used_tags = [];\nif (ragNode?.item?.json) {\n  const r = ragNode.item.json;\n  sources   = r.sources   || [];\n  used_tags = r.used_tags || [];\n}\n\nreturn {\n  result: (result || '').trim(),\n  status: (provider === 'Error') ? 'error' : 'success',\n  provider,\n  model_requested: requested.model,\n  model_used: actualModel,\n  timestamp: new Date().toISOString(),\n  usage: usage,\n  raw_response: raw,\n  sources,\n  used_tags\n};\n"
      },
      "id": "916597a3-e841-467c-86ea-dc8f5eae5b10",
      "name": "Format Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1152,
        832
      ]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {}
      },
      "id": "7631457b-479a-4e12-ab21-3403bd8629cf",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [
        1376,
        832
      ]
    }
  ],
  "pinData": {},
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Extract Fields",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Fields": {
      "main": [
        [
          {
            "node": "without rag?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "without rag?": {
      "main": [
        [
          {
            "node": "Is groq?",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "RAG Query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "RAG Query": {
      "main": [
        [
          {
            "node": "Build Augmented Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Augmented Prompt": {
      "main": [
        [
          {
            "node": "Is groq?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is groq?": {
      "main": [
        [
          {
            "node": "Basic LLM Chain1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is openrouter?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is openrouter?": {
      "main": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is mistralAPI?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is mistralAPI?": {
      "main": [
        [
          {
            "node": "Call mistralAPI",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is OpenAI?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is OpenAI?": {
      "main": [
        [
          {
            "node": "Call OpenAI",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is Anthropic?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is Anthropic?": {
      "main": [
        [
          {
            "node": "Call Claude",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is HuggingFace?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is HuggingFace?": {
      "main": [
        [
          {
            "node": "Call Hugging Face",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is Mistral?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is Mistral?": {
      "main": [
        [
          {
            "node": "Call Ollama",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Call Llama (Default)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call OpenAI": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Claude": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Hugging Face": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call mistralAPI": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Ollama": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Llama (Default)": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Groq Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "Groq Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Groq Chat Model2": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain1",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "Basic LLM Chain1": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Response": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": true,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "4bcf42dd-2291-4832-8e39-24eb7c891c2b",
  "meta": {
    "instanceId": "5e9f1d1029083353f9423560cb0b3070390ad03855815e064cf1d2e50cd094b4"
  },
  "id": "wXIZovoTkBVpyYOp",
  "tags": []
}