{
  "name": "RAG_router_v3",
  "nodes": [
    {
      "parameters": {},
      "id": "4e89858a-f6c8-4c8e-a5b1-a3d187a1cfcb",
      "name": "Execute Workflow Trigger",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1,
      "position": [
        -2688,
        944
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "keep-model",
              "name": "model",
              "value": "={{ $json.model }}",
              "type": "string"
            },
            {
              "id": "keep-prompt",
              "name": "prompt",
              "value": "={{ $json.prompt }}",
              "type": "string"
            },
            {
              "id": "keep-system",
              "name": "system",
              "value": "={{ $json.system || '' }}",
              "type": "string"
            },
            {
              "id": "keep-rag",
              "name": "rag",
              "value": "={{ $json.rag }}",
              "type": "string"
            },
            {
              "id": "keep-topk",
              "name": "rag_top_k",
              "value": "={{ Number($json.rag_top_k) || 5 }}",
              "type": "string"
            },
            {
              "id": "keep-thr",
              "name": "rag_score_threshold",
              "value": "={{ Number($json.rag_score_threshold) || 0.45 }}",
              "type": "string"
            },
            {
              "id": "keep-key",
              "name": "rag_api_key",
              "value": "={{ $json.rag_api_key }}",
              "type": "string"
            },
            {
              "id": "keep-tags",
              "name": "rag_tags",
              "value": "={{ Array.isArray($json.rag_tags) ? $json.rag_tags : [] }}",
              "type": "string"
            },
            {
              "id": "keep-hf",
              "name": "hf_model",
              "value": "={{ $json.hf_model }}",
              "type": "string"
            },
            {
              "id": "keep-openai",
              "name": "openai_model",
              "value": "={{ $json.openai_model }}",
              "type": "string"
            },
            {
              "id": "keep-claude",
              "name": "claude_model",
              "value": "={{ $json.claude_model }}",
              "type": "string"
            },
            {
              "id": "keep-ollama",
              "name": "ollama_model",
              "value": "={{ $json.ollama_model || $json.model || 'llama3' }}",
              "type": "string"
            },
            {
              "id": "keep-mistral",
              "name": "mistral_model",
              "value": "={{ $json.mistral_model }}",
              "type": "string"
            },
            {
              "id": "4b68771f-f185-4c92-8c8b-01d51033f615",
              "name": "conversation_id",
              "value": "={{ $json.conversation_id }}",
              "type": "string"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "id": "b400fcdf-de80-4d7f-a422-3236edd4b65a",
      "name": "Context (original fields)",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -2464,
        944
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "no-rag",
              "leftValue": "={{ $json.rag }}",
              "rightValue": "true",
              "operator": {
                "type": "string",
                "operation": "notEquals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "36975b74-0b6f-45d4-ac2c-8a7901fae188",
      "name": "without rag?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -2240,
        944
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://rag-backend:8082/query",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "x-api-key",
              "value": "={{ $('Context (original fields)').item.json.rag_api_key }}"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  query: $('Context (original fields)').item.json.prompt,\n  top_k: Number($('Context (original fields)').item.json.rag_top_k) || 5,\n  score_threshold: Number($('Context (original fields)').item.json.rag_score_threshold) || 0.45,\n  tags: Array.isArray($('Context (original fields)').item.json.rag_tags) ? $('Context (original fields)').item.json.rag_tags : []\n}) }}",
        "options": {
          "timeout": 300000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2016,
        1040
      ],
      "id": "97c7ea64-38d5-48c5-a616-d61823a4a43d",
      "name": "RAG Query"
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Build Augmented Prompt — per-item safe + Memory injection\nconst j = ($json && typeof $json === 'object') ? $json : {};\n\n// 1) Basis-Prompt (unverfälscht, falls vorhanden)\nconst basePrompt = j._original_prompt ?? j.prompt ?? \"\";\n\n// 2) Memory aufbereiten\nconst mem = j.memory || {};\nconst summary = (mem.summary || \"\").trim();\nconst history = Array.isArray(mem.history) ? mem.history.slice(-8) : []; // letzte 8 Einträge\n\nfunction fmt(m) {\n  const role = (m.role === 'assistant') ? 'Assistant' : 'User';\n  return `${role}: ${String(m.content || '').trim()}`;\n}\nconst histText = history.map(fmt).join('\\n');\n\nconst memParts = [];\nif (summary) memParts.push(`Zusammenfassung:\\n${summary}`);\nif (histText) memParts.push(`Letzte Nachrichten:\\n${histText}`);\n\nconst memoryBlock = memParts.length\n  ? `\\n\\n# Gesprächsspeicher\\n${memParts.join('\\n\\n')}`\n  : \"\";\n\n// 3) RAG-Kontext (falls vorhanden)\nlet docs = [];\nif (Array.isArray(j.docs)) docs = j.docs;\nelse if (Array.isArray(j.documents)) docs = j.documents;\nelse if (Array.isArray(j.matches)) docs = j.matches.map(m => m.document || m);\n\nfunction toEntry(d){\n  const text = d.text || d.content || d.page_content || d.pageContent || d.body || '';\n  const meta = d.metadata || d.meta || {};\n  const src  = meta.source || meta.file || meta.path || meta.url || meta.name || '';\n  return { text: String(text), source: String(src) };\n}\nconst entries = docs.map(toEntry).filter(e => e.text);\nconst contextText = entries.map((e, i) => `#${i+1} ${e.text}`).join('\\n\\n');\n\nconst sources = entries\n  .map((e, i) => ({ id: i+1, source: e.source }))\n  .filter(s => s.source);\n\nconst used_tags = Array.isArray(j.used_tags) ? j.used_tags\n                  : (Array.isArray(j.rag_tags) ? j.rag_tags : []);\n\nconst useRag = !!j.rag;\nconst contextBlock = (useRag && contextText)\n  ? `\\n\\n# Kontext (RAG)\\n${contextText}`\n  : \"\";\n\n// 4) Finaler Prompt = Basis + Memory + (optional) RAG\nconst augmentedPrompt = [basePrompt, memoryBlock, contextBlock]\n  .filter(Boolean)\n  .join(\"\");\n\nreturn { json: {\n  ...j,\n  prompt: augmentedPrompt,\n  sources,\n  used_tags\n}};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1792,
        944
      ],
      "id": "d7f37b11-f439-483e-8f6d-bb78e000671f",
      "name": "Build Augmented Prompt"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-groq",
              "leftValue": "={{ $json.model }}",
              "rightValue": "groq",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "8f08a79c-d948-4334-9c3f-8ffe9e0c01d9",
      "name": "Is groq?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -1568,
        944
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-openrouter",
              "leftValue": "={{ $json.model }}",
              "rightValue": "openrouter",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "3ce39500-555f-449e-bb4c-9a72c6faa9d2",
      "name": "Is openrouter?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -1344,
        1136
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-mistralapi",
              "leftValue": "={{ $json.model }}",
              "rightValue": "mistralapi",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "af90758a-b5b3-45be-bb1b-ef5cd7e4bd05",
      "name": "Is mistralAPI?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -1120,
        1280
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-openai",
              "leftValue": "={{ $json.model }}",
              "rightValue": "openai",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "81f0d0f0-8a68-4fcf-92f3-ba8fad049f37",
      "name": "Is OpenAI?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -896,
        1376
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-anthropic",
              "leftValue": "={{ $json.model }}",
              "rightValue": "anthropic",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "64a8112a-581a-4275-b2d4-e7963e4fd145",
      "name": "Is Anthropic?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -672,
        1472
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-hf",
              "leftValue": "={{ $json.model }}",
              "rightValue": "huggingface",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "ce078acc-6da4-4b85-bc38-f7811690933c",
      "name": "Is HuggingFace?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -448,
        1568
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-mistral",
              "leftValue": "={{ $json.model }}",
              "rightValue": "mistral",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "c67f4047-fffc-493a-be70-329b6629379e",
      "name": "Is Mistral?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -224,
        1664
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: $json.openai_model,\n  messages: [\n    ...(($('Context (original fields)').first().json.system || '').trim() ? [{ role: 'system', content: $('Context (original fields)').first().json.system }] : []),\n    { role: 'user', content: $json.prompt }\n  ],\n  max_tokens: 1000,\n  temperature: 0.7\n}) }}",
        "options": {}
      },
      "id": "77517c03-72e9-4246-8c8e-822c5009ed39",
      "name": "Call OpenAI",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        64,
        992
      ],
      "credentials": {
        "openAiApi": {
          "id": "xpFTPLasPN9qcrAU",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: $json.claude_model,\n  max_tokens: 1000,\n  messages: [{ role: 'user', content: $json.prompt }],\n  ...((($('Context (original fields)').first().json.system || '').trim()) ? { system: $('Context (original fields)').first().json.system } : {})\n}) }}",
        "options": {}
      },
      "id": "c9526557-e087-4695-b2fd-1bc6d98964cd",
      "name": "Call Claude",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        64,
        1184
      ],
      "credentials": {
        "anthropicApi": {
          "id": "NwPymGLQdk29P5fi",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api-inference.huggingface.co/models/{{ $json.hf_model }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "huggingFaceApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  inputs: (($('Context (original fields)').first().json.system || '').trim()) ? ($('Context (original fields)').first().json.system + '\\n\\n' + $json.prompt) : $json.prompt,\n  parameters: { max_length: 500, temperature: 0.7, do_sample: true, return_full_text: false }\n}) }}",
        "options": {}
      },
      "id": "54071bd9-3d9c-4a95-8d56-512ffdfb54b9",
      "name": "Call Hugging Face",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        64,
        1376
      ],
      "credentials": {
        "huggingFaceApi": {
          "id": "QO87qgUFRrbiQqXv",
          "name": "HuggingFaceApi account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.mistral.ai/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "mistralCloudApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: $json.mistral_model,\n  messages: [\n    { role: 'system', content: ($('Context (original fields)').first().json.system || 'Du bist ein hilfsbereiter Assistent.') },\n    { role: 'user', content: $json.prompt }\n  ],\n  max_tokens: 200,\n  temperature: 0.7\n}) }}",
        "options": {}
      },
      "id": "6cf0a06e-f580-4773-b4fc-3bde1dd6b2e0",
      "name": "Call mistralAPI",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        64,
        800
      ],
      "credentials": {
        "mistralCloudApi": {
          "id": "cp078sOI6OYLKqiI",
          "name": "Mistral Cloud API-key"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://ollama:11434/api/generate",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: ($json.ollama_model) ?? ($('Context (original fields)').item.json.ollama_model ?? $('Context (original fields)').item.json.model ?? 'llama3'),\n  prompt: ($json.prompt) ?? ($('Context (original fields)').item.json.prompt ?? ''),\n  stream: false,\n  options: {\n    temperature: (typeof $json.temperature === 'number') ? $json.temperature : 0.7,\n    top_p:       (typeof $json.top_p === 'number')       ? $json.top_p       : 0.9,\n    num_predict: (typeof $json.num_predict === 'number') ? $json.num_predict : 600\n  }\n}) }}",
        "options": {
          "timeout": 300000
        }
      },
      "id": "54edbcb8-7cde-43d3-a49d-e91eaa2c01cc",
      "name": "Call Ollama",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        64,
        1568
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://ollama:11434/api/generate",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: 'llama3',\n  prompt: (($('Context (original fields)').first().json.system || '').trim()) ? ($('Context (original fields)').first().json.system + '\\n\\n' + $json.prompt) : $json.prompt,\n  stream: false,\n  options: { temperature: 0.7, num_predict: 500 }\n}) }}",
        "options": {}
      },
      "id": "72be1f85-6fc9-44df-a080-fee4e8a7b039",
      "name": "Call Llama (Default)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        64,
        1760
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "c6cdfd6f-7e91-493c-b4ab-a565d824584c",
              "name": "sources",
              "value": "",
              "type": "string"
            },
            {
              "id": "f3453492-81cc-4ecf-bc2e-66ca20087ff3",
              "name": "used_tags",
              "value": "",
              "type": "string"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -2016,
        848
      ],
      "id": "17675d88-b0fc-4e8d-9aa3-1d1efb3828d0",
      "name": "No RAG Context"
    },
    {
      "parameters": {
        "model": "moonshotai/kimi-k2-instruct",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        16,
        224
      ],
      "id": "d2502226-41dc-4da0-b3bf-458e63aa72d9",
      "name": "Moonshot / Kimi K2",
      "credentials": {
        "groqApi": {
          "id": "mhumLW1ZXnpB1MfM",
          "name": "Groq account"
        }
      }
    },
    {
      "parameters": {
        "model": "openai/gpt-oss-120b",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        144,
        224
      ],
      "id": "d83c61d6-6ee3-4338-936f-f9fa6ca4415f",
      "name": "GPT-OSS-120b",
      "credentials": {
        "groqApi": {
          "id": "mhumLW1ZXnpB1MfM",
          "name": "Groq account"
        }
      }
    },
    {
      "parameters": {
        "model": "qwen/qwen3-32b",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        16,
        624
      ],
      "id": "05d1a3f1-34fa-4ecc-a619-ccda6146691e",
      "name": "qwen3",
      "credentials": {
        "groqApi": {
          "id": "mhumLW1ZXnpB1MfM",
          "name": "Groq account"
        }
      }
    },
    {
      "parameters": {
        "model": "gemma2-9b-it",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        144,
        624
      ],
      "id": "1eb79001-e890-4a6a-bfd5-c16a648d6375",
      "name": "gemma-it",
      "credentials": {
        "groqApi": {
          "id": "mhumLW1ZXnpB1MfM",
          "name": "Groq account"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Response Formatter — per-item safe (no .first(), no .item())\n// Liest den Original-Kontext über $items('Context (original fields)') ein,\n// damit prompt/system/conversation_id zuverlässig vorhanden sind – auch wenn\n// der Provider-Call $json überschreibt.\n\n//// ------ Kontext holen ------\nlet requested = {};\ntry {\n  const ctx = $items('Context (original fields)', 0) || [];\n  requested = (Array.isArray(ctx) && ctx[0] && ctx[0].json) ? ctx[0].json : {};\n} catch { requested = {}; }\n\n// Provider-Rohdaten sind im aktuellen Item:\nlet data = $json;\n\n//// ------ Stream-Parser (NDJSON / SSE) ------\nfunction parseNdjsonString(s){\n  try {\n    const lines = String(s).trim().split('\\n').filter(Boolean);\n    return lines.map(l=>JSON.parse(l));\n  } catch { return null; }\n}\nfunction parseSseString(s){\n  const out=[];\n  for (const line of String(s).split('\\n')) {\n    const t=line.trim();\n    if (!t || !t.toLowerCase().startsWith('data:')) continue;\n    const p=t.slice(5).trim();\n    if (!p || p==='[DONE]') continue;\n    try { out.push(JSON.parse(p)); } catch {}\n  }\n  return out.length ? out : null;\n}\nfunction extractTextFromChunk(o){\n  if (typeof o?.response === 'string') return o.response;\n  const c = o?.choices && o.choices[0];\n  if (c) {\n    if (c.delta && typeof c.delta.content === 'string') return c.delta.content;\n    if (c.message && typeof c.message.content === 'string') return c.message.content;\n    if (typeof c.text === 'string') return c.text;\n    if (Array.isArray(c.content)) return c.content.map(x => typeof x.text==='string' ? x.text : '').join('');\n  }\n  if (typeof o?.content === 'string') return o.content;\n  if (typeof o?.output_text === 'string') return o.output_text;\n  if (typeof o?.text === 'string') return o.text;\n  return '';\n}\n\n//// ------ Normalisierung & Extraktion ------\nlet result, provider, actualModel, usage=null, raw=data;\n\n// Wenn der Provider ein String ist, in {data} packen\nif (typeof data === 'string') { raw={data}; data={data}; }\n\n// Streaming-Formate erkennen\nif (data && typeof data.data === 'string') {\n  let chunks = parseNdjsonString(data.data);\n  if (chunks && chunks.length) {\n    provider = 'Ollama';\n    actualModel = (chunks.find(o=>o.done===true)?.model) || chunks[0]?.model || requested.ollama_model;\n    result = chunks.map(extractTextFromChunk).filter(Boolean).join('').trim();\n    raw = { ndjson: chunks };\n  } else {\n    chunks = parseSseString(data.data);\n    if (chunks && chunks.length) {\n      provider = (chunks.find(o=>o?.provider) ? 'OpenRouter' : 'Groq/OpenAI-like');\n      actualModel = (chunks.find(o=>o?.model)?.model) || requested.model || requested.openai_model || requested.ollama_model;\n      result = chunks.map(extractTextFromChunk).filter(Boolean).join('').trim();\n      raw = { sse: chunks };\n    }\n  }\n}\n\n// Non-Streaming-Formate\nif (!result) {\n  if (data && data.choices?.[0]?.message) {\n    // OpenAI-like\n    result = data.choices[0].message.content;\n    provider = 'OpenAI';\n    actualModel = data.model || requested.openai_model;\n    usage = data.usage || null;\n  } else if (data && Array.isArray(data.content) && data.content[0]) {\n    // Anthropic-like\n    result = data.content[0].text || data.content[0].content;\n    provider = 'Claude/Anthropic';\n    actualModel = data.model || requested.claude_model;\n  } else if (Array.isArray(data) && data[0]?.generated_text) {\n    // HF pipeline (array)\n    result = data[0].generated_text;\n    provider = 'Hugging Face';\n    actualModel = requested.hf_model;\n  } else if (data && data.generated_text) {\n    // HF pipeline (object)\n    result = data.generated_text;\n    provider = 'Hugging Face';\n    actualModel = requested.hf_model;\n  } else if (data && typeof data.response === 'string') {\n    // Ollama\n    result = data.response;\n    provider = 'Ollama';\n    actualModel = data.model || requested.ollama_model;\n  } else if (data && data.text) {\n    // OpenRouter/Groq-like plain\n    result = data.text;\n    provider = 'OpenRouter/Groq-like';\n    actualModel = requested.model || requested.openai_model || requested.ollama_model;\n  } else if (data && data.error) {\n    result = `Error: ${data.error.message || JSON.stringify(data.error)}`;\n    provider = 'Error';\n    actualModel = 'N/A';\n  } else {\n    result = `Unexpected response format: ${JSON.stringify(data)}`;\n    provider = 'Unknown';\n    actualModel = 'N/A';\n  }\n}\n\n//// ------ Quellen, Tags & Label übernehmen ------\nconst sources = Array.isArray(requested.sources)\n  ? requested.sources\n  : (Array.isArray($json.sources) ? $json.sources : []);\nconst used_tags = Array.isArray(requested.used_tags)\n  ? requested.used_tags\n  : (Array.isArray(requested.rag_tags) ? requested.rag_tags : (Array.isArray($json.used_tags) ? $json.used_tags : []));\n\nconst inputLabel = requested.label ?? $json.label;\n\n//// ------ Rückgabe ------\nreturn { json: {\n  result: (result || '').trim(),\n  status: (provider === 'Error') ? 'error' : 'success',\n  provider,\n  model_requested: requested.model,\n  model_used: actualModel,\n  timestamp: new Date().toISOString(),\n  usage,\n  raw_response: raw,\n  sources,\n  used_tags,\n  original_prompt: requested._original_prompt ?? requested.prompt ?? $json.original_prompt ?? $json.prompt,\n  conversation_id: requested.conversation_id ?? $json.conversation_id,\n  label: inputLabel\n}};\n"
      },
      "id": "4c354ee7-9cde-4727-b8e6-d5038672d9c4",
      "name": "Format Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        352,
        1088
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ (($('Context (original fields)').first().json.system || '').trim()) ? $('Context (original fields)').first().json.system + \"\\n\\n\" + $json.prompt : $json.prompt }}",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        0,
        0
      ],
      "id": "ab76abd5-0396-419d-8917-73fd4b6eb6bd",
      "name": "groq"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ (($('Context (original fields)').first().json.system || '').trim()) ? $('Context (original fields)').first().json.system + \"\\n\\n\" + $json.prompt : $json.prompt }}",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        0,
        400
      ],
      "id": "99f7ec4d-07d7-42f9-8404-8dfd3a049dc7",
      "name": "openrouter"
    }
  ],
  "pinData": {},
  "connections": {
    "Execute Workflow Trigger": {
      "main": [
        [
          {
            "node": "Context (original fields)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Context (original fields)": {
      "main": [
        [
          {
            "node": "without rag?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "without rag?": {
      "main": [
        [
          {
            "node": "No RAG Context",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "RAG Query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "RAG Query": {
      "main": [
        [
          {
            "node": "Build Augmented Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Augmented Prompt": {
      "main": [
        [
          {
            "node": "Is groq?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is groq?": {
      "main": [
        [
          {
            "node": "groq",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is openrouter?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is openrouter?": {
      "main": [
        [
          {
            "node": "openrouter",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is mistralAPI?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is mistralAPI?": {
      "main": [
        [
          {
            "node": "Call mistralAPI",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is OpenAI?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is OpenAI?": {
      "main": [
        [
          {
            "node": "Call OpenAI",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is Anthropic?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is Anthropic?": {
      "main": [
        [
          {
            "node": "Call Claude",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is HuggingFace?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is HuggingFace?": {
      "main": [
        [
          {
            "node": "Call Hugging Face",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is Mistral?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is Mistral?": {
      "main": [
        [
          {
            "node": "Call Ollama",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Call Llama (Default)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call OpenAI": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Claude": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Hugging Face": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call mistralAPI": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Ollama": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Llama (Default)": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "No RAG Context": {
      "main": [
        [
          {
            "node": "Build Augmented Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Moonshot / Kimi K2": {
      "ai_languageModel": [
        [
          {
            "node": "groq",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "GPT-OSS-120b": {
      "ai_languageModel": [
        [
          {
            "node": "groq",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "qwen3": {
      "ai_languageModel": [
        [
          {
            "node": "openrouter",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "gemma-it": {
      "ai_languageModel": [
        [
          {
            "node": "openrouter",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "groq": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "openrouter": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "23426ad2-3db5-465c-b793-87ed3057f0e3",
  "meta": {
    "instanceId": "5e9f1d1029083353f9423560cb0b3070390ad03855815e064cf1d2e50cd094b4"
  },
  "id": "2cmATLhSNBMN3a2H",
  "tags": [
    {
      "createdAt": "2025-08-15T08:00:40.082Z",
      "updatedAt": "2025-08-15T08:00:40.082Z",
      "id": "MIGc52SFD5ylOxsf",
      "name": "Subflow"
    }
  ]
}