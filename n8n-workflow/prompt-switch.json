{
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "llm",
        "responseMode": "lastNode"
      },
      "id": "Webhook",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [100, 300]
    },
    {
      "parameters": {
        "code": "const { prompt, model, openai_api_key = null } = $json;\n\nif (!prompt || !model) {\n  throw new Error('prompt and model required');\n}\n\nreturn [{\n  json: {\n    prompt,\n    model,\n    openai_api_key\n  }\n}];"
      },
      "id": "Input Check",
      "name": "Input Check",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [300, 300]
    },
    {
      "parameters": {
        "value1": "={{ $json.model }}",
        "rules": [
          {
            "operation": "equal",
            "value2": "openai"
          },
          {
            "operation": "equal",
            "value2": "ollama"
          }
        ]
      },
      "id": "Switch Model",
      "name": "Switch Model",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 1,
      "position": [500, 300]
    },
    {
      "parameters": {
        "url": "https://api.openai.com/v1/chat/completions",
        "method": "POST",
        "authentication": "none",
        "jsonParameters": true,
        "responseFormat": "json",
        "bodyParametersJson": "={\n  \"model\": \"gpt-4\",\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"{{$json.prompt}}\" }\n  ]\n}",
        "headerParametersJson": "={\n  \"Authorization\": \"Bearer {{$json.openai_api_key}}\",\n  \"Content-Type\": \"application/json\"\n}"
      },
      "id": "Call OpenAI",
      "name": "Call OpenAI",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [700, 200]
    },
    {
      "parameters": {
        "url": "http://ollama:11434/api/generate",
        "method": "POST",
        "jsonParameters": true,
        "responseFormat": "json",
        "bodyParametersJson": "={\n  \"model\": \"mistral\",\n  \"prompt\": \"{{$json.prompt}}\"\n}"
      },
      "id": "Call Ollama",
      "name": "Call Ollama",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [700, 400]
    },
    {
      "parameters": {
        "code": "return [\n  {\n    json: {\n      response: $json.choices?.[0]?.message?.content || $json.response || $json.output || $json,\n      model: $json.model || (typeof $json.choices !== 'undefined' ? 'openai' : 'ollama')\n    }\n  }\n];"
      },
      "id": "Wrap Response",
      "name": "Wrap Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 1,
      "position": [900, 300]
    },
    {
      "parameters": {},
      "id": "Respond to Webhook",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.noOp",
      "typeVersion": 1,
      "position": [1100, 300]
    }
  ],
  "connections": {
    "Webhook": {
      "main": [["Input Check"]]
    },
    "Input Check": {
      "main": [["Switch Model"]]
    },
    "Switch Model": {
      "main": [
        ["Call OpenAI"],
        ["Call Ollama"]
      ]
    },
    "Call OpenAI": {
      "main": [["Wrap Response"]]
    },
    "Call Ollama": {
      "main": [["Wrap Response"]]
    },
    "Wrap Response": {
      "main": [["Respond to Webhook"]]
    }
  },
  "active": false,
  "settings": {},
  "name": "LLM Router"
}
