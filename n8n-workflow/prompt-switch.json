{
  "name": "Prompt Router (Switch)",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "prompt"
      },
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [100, 300]
    },
    {
      "parameters": {
        "conditions": {
          "string": [
            {
              "value1": "={{$json.model}}",
              "value2": "openai"
            }
          ]
        }
      },
      "name": "Switch OpenAI",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 1,
      "position": [300, 200]
    },
    {
      "parameters": {
        "conditions": {
          "string": [
            {
              "value1": "={{$json.model}}",
              "value2": "ollama"
            }
          ]
        }
      },
      "name": "Switch Ollama",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 1,
      "position": [300, 400]
    },
    {
      "parameters": {
        "requestMethod": "POST",
        "url": "https://api.openai.com/v1/chat/completions",
        "jsonParameters": true,
        "options": {},
        "bodyParametersJson": "{\n  \"model\": \"gpt-4\",\n  \"messages\": [\n    { \"role\": \"user\", \"content\": \"={{$json.prompt}}\" }\n  ]\n}",
        "headersJson": "{\n  \"Authorization\": \"Bearer {{$json.openai_api_key}}\",\n  \"Content-Type\": \"application/json\"\n}"
      },
      "name": "Call OpenAI",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [500, 200]
    },
    {
      "parameters": {
        "requestMethod": "POST",
        "url": "http://ollama:11434/api/generate",
        "jsonParameters": true,
        "options": {},
        "bodyParametersJson": "{\n  \"model\": \"mistral\",\n  \"prompt\": \"={{$json.prompt}}\"\n}"
      },
      "name": "Call Ollama",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [500, 400]
    },
    {
      "parameters": {
        "functionCode": "const data = $json;\n\n// OpenAI response\nif (data.choices && data.choices[0]) {\n  return [{ json: { result: data.choices[0].message.content } }];\n}\n\n// Ollama response\nif (data.response) {\n  return [{ json: { result: data.response } }];\n}\n\nreturn [{ json: { result: 'No response.' } }];"
      },
      "name": "Wrap Response",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [700, 300]
    },
    {
      "parameters": {
        "responseMode": "lastNode",
        "responseData": "firstEntryJson"
      },
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [900, 300]
    }
  ],
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Switch OpenAI",
            "type": "main",
            "index": 0
          },
          {
            "node": "Switch Ollama",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch OpenAI": {
      "main": [
        [
          {
            "node": "Call OpenAI",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Switch Ollama": {
      "main": [
        [
          {
            "node": "Call Ollama",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call OpenAI": {
      "main": [
        [
          {
            "node": "Wrap Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Ollama": {
      "main": [
        [
          {
            "node": "Wrap Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wrap Response": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "versionId": "v1"
}
