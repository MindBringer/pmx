{
  "name": "RAG_Router_Subflow",
  "nodes": [
    {
      "parameters": {},
      "id": "trigger",
      "name": "Execute Workflow Trigger",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1,
      "position": [-1888, 688]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            { "id": "keep-model", "name": "model", "value": "={{ $json.model }}", "type": "string" },
            { "id": "keep-prompt", "name": "prompt", "value": "={{ $json.prompt }}", "type": "string" },
            { "id": "keep-system", "name": "system", "value": "={{ $json.system || '' }}", "type": "string" },
            { "id": "keep-rag", "name": "rag", "value": "={{ $json.rag }}", "type": "string" },
            { "id": "keep-topk", "name": "rag_top_k", "value": "={{ Number($json.rag_top_k) || 5 }}", "type": "string" },
            { "id": "keep-thr", "name": "rag_score_threshold", "value": "={{ Number($json.rag_score_threshold) || 0.45 }}", "type": "string" },
            { "id": "keep-key", "name": "rag_api_key", "value": "={{ $json.rag_api_key }}", "type": "string" },
            { "id": "keep-tags", "name": "rag_tags", "value": "={{ Array.isArray($json.rag_tags) ? $json.rag_tags : [] }}", "type": "string" },
            { "id": "keep-hf", "name": "hf_model", "value": "={{ $json.hf_model }}", "type": "string" },
            { "id": "keep-openai", "name": "openai_model", "value": "={{ $json.openai_model }}", "type": "string" },
            { "id": "keep-claude", "name": "claude_model", "value": "={{ $json.claude_model }}", "type": "string" },
            { "id": "keep-ollama", "name": "ollama_model", "value": "={{ $json.ollama_model || $json.model || 'llama3' }}", "type": "string" },
            { "id": "keep-mistral", "name": "mistral_model", "value": "={{ $json.mistral_model }}", "type": "string" }
          ]
        },
        "options": {}
      },
      "id": "context",
      "name": "Context (original fields)",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [-1664, 688]
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 1 },
          "conditions": [
            {
              "id": "no-rag",
              "leftValue": "={{ $json.rag }}",
              "rightValue": "true",
              "operator": { "type": "string", "operation": "notEquals" }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "if-no-rag",
      "name": "without rag?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [-1440, 688]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://rag-backend:8082/query",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            { "name": "Content-Type", "value": "application/json" },
            { "name": "x-api-key", "value": "={{ $('Context (original fields)').item.json.rag_api_key }}" }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  query: $('Context (original fields)').item.json.prompt,\n  top_k: Number($('Context (original fields)').item.json.rag_top_k) || 5,\n  score_threshold: Number($('Context (original fields)').item.json.rag_score_threshold) || 0.45,\n  tags: Array.isArray($('Context (original fields)').item.json.rag_tags) ? $('Context (original fields)').item.json.rag_tags : []\n}) }}",
        "options": { "timeout": 300000 }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [-1216, 752],
      "id": "rag-query",
      "name": "RAG Query"
    },
    {
      "parameters": {
        "jsCode": "// Eingaben\nconst inData = $input.first().json || {};\nconst base   = $('Context (original fields)').first().json || {};\n\n// Quellen hÃ¼bsch formatieren (max 8)\nconst sources = Array.isArray(inData.sources) ? inData.sources : [];\nconst lines = sources.slice(0, 8).map((s, i) => {\n  const fn    = s?.meta?.filename || s?.filename || `Quelle ${i+1}`;\n  const score = (typeof s?.score === 'number') ? ` (score: ${s.score.toFixed(3)})` : '';\n  const snip  = s?.snippet ?? s?.content ?? s?.meta?.text ?? '';\n  const short = String(snip).replace(/\\s+/g, ' ').trim().slice(0, 600);\n  return `- ${fn}${score}: ${short}`;\n});\n\nconst contextBlock = lines.length ? `Kontext aus Firmendaten:\\n${lines.join('\\n')}\\n\\n` : '';\nconst systemBlock  = (base.system && String(base.system).trim()) ? String(base.system).trim() + '\\n\\n' : '';\nconst userPrompt   = String(base.prompt ?? '').trim();\nconst augmented    = `${systemBlock}${contextBlock}Frage: ${userPrompt}`;\n\nconst modelOllama = base.ollama_model || base.model || 'llama3';\nconst temperature = typeof base.temperature === 'number' ? base.temperature : 0.7;\nconst top_p       = typeof base.top_p === 'number' ? base.top_p : 0.9;\nconst num_predict = typeof base.num_predict === 'number' ? base.num_predict : 600;\n\nreturn {\n  prompt: augmented,\n  system: base.system || '',\n  model: base.model,\n  ollama_model: modelOllama,\n  hf_model: base.hf_model,\n  openai_model: base.openai_model,\n  claude_model: base.claude_model,\n  mistral_model: base.mistral_model,\n  temperature, top_p, num_predict,\n  augmented_prompt: augmented,\n  sources,\n  used_tags: inData.used_tags || [],\n  rag_suggested_answer: inData.answer || null\n};"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [-992, 752],
      "id": "build-aug",
      "name": "Build Augmented Prompt"
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 1 },
          "conditions": [
            { "id": "is-groq", "leftValue": "={{ $json.model }}", "rightValue": "groq", "operator": { "type": "string", "operation": "equals" } }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "is-groq",
      "name": "Is groq?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [-768, 688]
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 1 },
          "conditions": [
            { "id": "is-openrouter", "leftValue": "={{ $json.model }}", "rightValue": "openrouter", "operator": { "type": "string", "operation": "equals" } }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "is-openrouter",
      "name": "Is openrouter?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [-544, 880]
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 1 },
          "conditions": [
            { "id": "is-mistralapi", "leftValue": "={{ $json.model }}", "rightValue": "mistralapi", "operator": { "type": "string", "operation": "equals" } }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "is-mistralapi",
      "name": "Is mistralAPI?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [-320, 1024]
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 1 },
          "conditions": [
            { "id": "is-openai", "leftValue": "={{ $json.model }}", "rightValue": "openai", "operator": { "type": "string", "operation": "equals" } }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "is-openai",
      "name": "Is OpenAI?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [-96, 1120]
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 1 },
          "conditions": [
            { "id": "is-anthropic", "leftValue": "={{ $json.model }}", "rightValue": "anthropic", "operator": { "type": "string", "operation": "equals" } }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "is-anthropic",
      "name": "Is Anthropic?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [128, 1216]
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 1 },
          "conditions": [
            { "id": "is-hf", "leftValue": "={{ $json.model }}", "rightValue": "huggingface", "operator": { "type": "string", "operation": "equals" } }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "is-hf",
      "name": "Is HuggingFace?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [352, 1312]
    },
    {
      "parameters": {
        "conditions": {
          "options": { "caseSensitive": true, "leftValue": "", "typeValidation": "strict", "version": 1 },
          "conditions": [
            { "id": "is-mistral", "leftValue": "={{ $json.model }}", "rightValue": "mistral", "operator": { "type": "string", "operation": "equals" } }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "is-mistral",
      "name": "Is Mistral?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [576, 1408]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: $json.openai_model,\n  messages: [\n    ...(($('Context (original fields)').first().json.system || '').trim() ? [{ role: 'system', content: $('Context (original fields)').first().json.system }] : []),\n    { role: 'user', content: $json.prompt }\n  ],\n  max_tokens: 1000,\n  temperature: 0.7\n}) }}",
        "options": {}
      },
      "id": "call-openai",
      "name": "Call OpenAI",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [864, 736],
      "credentials": { "openAiApi": { "id": "xpFTPLasPN9qcrAU", "name": "OpenAi account" } }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: $json.claude_model,\n  max_tokens: 1000,\n  messages: [{ role: 'user', content: $json.prompt }],\n  ...((($('Context (original fields)').first().json.system || '').trim()) ? { system: $('Context (original fields)').first().json.system } : {})\n}) }}",
        "options": {}
      },
      "id": "call-claude",
      "name": "Call Claude",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [864, 928],
      "credentials": { "anthropicApi": { "id": "NwPymGLQdk29P5fi", "name": "Anthropic account" } }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api-inference.huggingface.co/models/{{ $json.hf_model }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "huggingFaceApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  inputs: (($('Context (original fields)').first().json.system || '').trim()) ? ($('Context (original fields)').first().json.system + '\\n\\n' + $json.prompt) : $json.prompt,\n  parameters: { max_length: 500, temperature: 0.7, do_sample: true, return_full_text: false }\n}) }}",
        "options": {}
      },
      "id": "call-hf",
      "name": "Call Hugging Face",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [864, 1120],
      "credentials": { "huggingFaceApi": { "id": "QO87qgUFRrbiQqXv", "name": "HuggingFaceApi account" } }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.mistral.ai/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "mistralCloudApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: $json.mistral_model,\n  messages: [\n    { role: 'system', content: ($('Context (original fields)').first().json.system || 'Du bist ein hilfsbereiter Assistent.') },\n    { role: 'user', content: $json.prompt }\n  ],\n  max_tokens: 200,\n  temperature: 0.7\n}) }}",
        "options": {}
      },
      "id": "call-mistralapi",
      "name": "Call mistralAPI",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [864, 544],
      "credentials": { "mistralCloudApi": { "id": "cp078sOI6OYLKqiI", "name": "Mistral Cloud API-key" } }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://ollama:11434/api/generate",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: ($json.ollama_model) ?? ($('Context (original fields)').item.json.ollama_model ?? $('Context (original fields)').item.json.model ?? 'llama3'),\n  prompt: ($json.prompt) ?? ($('Context (original fields)').item.json.prompt ?? ''),\n  stream: false,\n  options: {\n    temperature: (typeof $json.temperature === 'number') ? $json.temperature : 0.7,\n    top_p:       (typeof $json.top_p === 'number')       ? $json.top_p       : 0.9,\n    num_predict: (typeof $json.num_predict === 'number') ? $json.num_predict : 600\n  }\n}) }}",
        "options": { "timeout": 300000 }
      },
      "id": "call-ollama",
      "name": "Call Ollama",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [864, 1312]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://ollama:11434/api/generate",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: 'llama3',\n  prompt: (($('Context (original fields)').first().json.system || '').trim()) ? ($('Context (original fields)').first().json.system + '\\n\\n' + $json.prompt) : $json.prompt,\n  stream: false,\n  options: { temperature: 0.7, num_predict: 500 }\n}) }}",
        "options": {}
      },
      "id": "call-llama-default",
      "name": "Call Llama (Default)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [864, 1504]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ (($('Context (original fields)').first().json.system || '').trim()) ? $('Context (original fields)').first().json.system + \"\\n\\n\" + $json.prompt : $json.prompt }}",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [800, 144],
      "id": "lc-basic",
      "name": "Basic LLM Chain"
    },
    {
      "parameters": { "options": {} },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [816, 368],
      "id": "lc-openrouter",
      "name": "OpenRouter Chat Model",
      "credentials": { "openRouterApi": { "id": "h5qqZ7le0CZSkkCh", "name": "OpenRouter account" } }
    },
    {
      "parameters": { "model": "qwen/qwen3-32b", "options": {} },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [944, 368],
      "id": "lc-groq-1",
      "name": "Groq Chat Model1",
      "credentials": { "groqApi": { "id": "mhumLW1ZXnpB1MfM", "name": "Groq account" } }
    },
    {
      "parameters": {
        "jsCode": "// Response Formatter (angepasst auf Subflow)\nconst requested = $('Context (original fields)').first().json || {};\nconst item = $input.first();\nlet data = item.json;\n\nfunction parseNdjsonString(s){try{const lines=String(s).trim().split('\\n').filter(Boolean);return lines.map(l=>JSON.parse(l));}catch{return null;}}\nfunction parseSseString(s){const out=[];for(const line of String(s).split('\\n')){const t=line.trim();if(!t||!t.toLowerCase().startsWith('data:'))continue;const p=t.slice(5).trim();if(!p||p==='[DONE]')continue;try{out.push(JSON.parse(p));}catch{}}return out.length?out:null;}\nfunction extractTextFromChunk(o){if(typeof o.response==='string')return o.response;const c=o.choices&&o.choices[0];if(c){if(c.delta&&typeof c.delta.content==='string')return c.delta.content;if(c.message&&typeof c.message.content==='string')return c.message.content;if(typeof c.text==='string')return c.text;if(Array.isArray(c.content))return c.content.map(x=>typeof x.text==='string'?x.text:'').join('');}\nif(typeof o.content==='string')return o.content; if(typeof o.output_text==='string')return o.output_text; if(typeof o.text==='string')return o.text; return '';}\n\nlet result, provider, actualModel, usage=null, raw=data;\nif(typeof data==='string'){raw={data};data={data};}\nif(data&&typeof data.data==='string'){\n  let chunks=parseNdjsonString(data.data);\n  if(chunks&&chunks.length){provider='Ollama';actualModel=(chunks.find(o=>o.done===true)?.model)||chunks[0]?.model||requested.ollama_model;result=chunks.map(extractTextFromChunk).filter(Boolean).join('').trim();raw={ndjson:chunks};}\n  else{chunks=parseSseString(data.data);if(chunks&&chunks.length){provider=(chunks.find(o=>o?.provider)?'OpenRouter':'Groq/OpenAI-like');actualModel=(chunks.find(o=>o?.model)?.model)||requested.model||requested.openai_model||requested.ollama_model;result=chunks.map(extractTextFromChunk).filter(Boolean).join('').trim();raw={sse:chunks};}}\n}\nif(!result){\n  if(data&&data.choices?.[0]?.message){result=data.choices[0].message.content;provider='OpenAI';actualModel=data.model||requested.openai_model;usage=data.usage||null;}\n  else if(data&&Array.isArray(data.content)&&data.content[0]){result=data.content[0].text||data.content[0].content;provider='Claude/Anthropic';actualModel=data.model||requested.claude_model;}\n  else if(Array.isArray(data)&&data[0]?.generated_text){result=data[0].generated_text;provider='Hugging Face';actualModel=requested.hf_model;}\n  else if(data&&data.generated_text){result=data.generated_text;provider='Hugging Face';actualModel=requested.hf_model;}\n  else if(data&&typeof data.response==='string'){result=data.response;provider='Ollama';actualModel=data.model||requested.ollama_model;}\n  else if(data&&data.text){result=data.text;provider='OpenRouter';actualModel=requested.model||requested.openai_model||requested.ollama_model;}\n  else if(data&&data.error){result=`Error: ${data.error.message||JSON.stringify(data.error)}`;provider='Error';actualModel='N/A';}\n  else {result=`Unexpected response format: ${JSON.stringify(data)}`;provider='Unknown';actualModel='N/A';}\n}\n\nlet sources=[], used_tags=[]; try{const rag=$('build-aug').first().json||{}; if(Array.isArray(rag.sources))sources=rag.sources; if(Array.isArray(rag.used_tags))used_tags=rag.used_tags;}catch{}\n\nreturn {\n  result:(result||'').trim(),\n  status:(provider==='Error')?'error':'success',\n  provider,\n  model_requested: requested.model,\n  model_used: actualModel,\n  timestamp: new Date().toISOString(),\n  usage,\n  raw_response: raw,\n  sources,\n  used_tags\n};"
      },
      "id": "format-response",
      "name": "Format Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1152, 832]
    }
  ],
  "connections": {
    "Execute Workflow Trigger": { "main": [[{ "node": "Context (original fields)", "type": "main", "index": 0 }]] },
    "Context (original fields)": { "main": [[{ "node": "without rag?", "type": "main", "index": 0 }]] },
    "without rag?": {
      "main": [
        [{ "node": "Is groq?", "type": "main", "index": 0 }],
        [{ "node": "RAG Query", "type": "main", "index": 0 }]
      ]
    },
    "RAG Query": { "main": [[{ "node": "Build Augmented Prompt", "type": "main", "index": 0 }]] },
    "Build Augmented Prompt": { "main": [[{ "node": "Is groq?", "type": "main", "index": 0 }]] },
    "Is groq?": {
      "main": [
        [{ "node": "Format Response", "type": "main", "index": 0 }],
        [{ "node": "Is openrouter?", "type": "main", "index": 0 }]
      ]
    },
    "Is openrouter?": {
      "main": [
        [{ "node": "Format Response", "type": "main", "index": 0 }],
        [{ "node": "Is mistralAPI?", "type": "main", "index": 0 }]
      ]
    },
    "Is mistralAPI?": {
      "main": [
        [{ "node": "Call mistralAPI", "type": "main", "index": 0 }],
        [{ "node": "Is OpenAI?", "type": "main", "index": 0 }]
      ]
    },
    "Is OpenAI?": {
      "main": [
        [{ "node": "Call OpenAI", "type": "main", "index": 0 }],
        [{ "node": "Is Anthropic?", "type": "main", "index": 0 }]
      ]
    },
    "Is Anthropic?": {
      "main": [
        [{ "node": "Call Claude", "type": "main", "index": 0 }],
        [{ "node": "Is HuggingFace?", "type": "main", "index": 0 }]
      ]
    },
    "Is HuggingFace?": {
      "main": [
        [{ "node": "Call Hugging Face", "type": "main", "index": 0 }],
        [{ "node": "Is Mistral?", "type": "main", "index": 0 }]
      ]
    },
    "Is Mistral?": {
      "main": [
        [{ "node": "Call Ollama", "type": "main", "index": 0 }],
        [{ "node": "Call Llama (Default)", "type": "main", "index": 0 }]
      ]
    },
    "Call OpenAI": { "main": [[{ "node": "Format Response", "type": "main", "index": 0 }]] },
    "Call Claude": { "main": [[{ "node": "Format Response", "type": "main", "index": 0 }]] },
    "Call Hugging Face": { "main": [[{ "node": "Format Response", "type": "main", "index": 0 }]] },
    "Call mistralAPI": { "main": [[{ "node": "Format Response", "type": "main", "index": 0 }]] },
    "Call Ollama": { "main": [[{ "node": "Format Response", "type": "main", "index": 0 }]] },
    "Call Llama (Default)": { "main": [[{ "node": "Format Response", "type": "main", "index": 0 }]] },
    "OpenRouter Chat Model": {
      "ai_languageModel": [[{ "node": "Basic LLM Chain", "type": "ai_languageModel", "index": 0 }]]
    },
    "Groq Chat Model1": {
      "ai_languageModel": [[{ "node": "Basic LLM Chain", "type": "ai_languageModel", "index": 1 }]]
    }
  },
  "settings": { "executionOrder": "v1" },
  "active": false
}
