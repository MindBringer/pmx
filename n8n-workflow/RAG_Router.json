{
  "name": "RAG_Router",
  "nodes": [
    {
      "parameters": {},
      "id": "1eed496b-09ee-4510-8f72-99a91e6f806e",
      "name": "Execute Workflow Trigger",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1,
      "position": [
        -2752,
        992
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "keep-model",
              "name": "model",
              "value": "={{ $json.model }}",
              "type": "string"
            },
            {
              "id": "keep-prompt",
              "name": "prompt",
              "value": "={{ $json.prompt }}",
              "type": "string"
            },
            {
              "id": "keep-system",
              "name": "system",
              "value": "={{ $json.system || '' }}",
              "type": "string"
            },
            {
              "id": "keep-rag",
              "name": "rag",
              "value": "={{ $json.rag }}",
              "type": "string"
            },
            {
              "id": "keep-topk",
              "name": "rag_top_k",
              "value": "={{ Number($json.rag_top_k) || 5 }}",
              "type": "string"
            },
            {
              "id": "keep-thr",
              "name": "rag_score_threshold",
              "value": "={{ Number($json.rag_score_threshold) || 0.45 }}",
              "type": "string"
            },
            {
              "id": "keep-key",
              "name": "rag_api_key",
              "value": "={{ $json.rag_api_key }}",
              "type": "string"
            },
            {
              "id": "keep-tags",
              "name": "rag_tags",
              "value": "={{ Array.isArray($json.rag_tags) ? $json.rag_tags : [] }}",
              "type": "string"
            },
            {
              "id": "keep-hf",
              "name": "hf_model",
              "value": "={{ $json.hf_model }}",
              "type": "string"
            },
            {
              "id": "keep-openai",
              "name": "openai_model",
              "value": "={{ $json.openai_model }}",
              "type": "string"
            },
            {
              "id": "keep-claude",
              "name": "claude_model",
              "value": "={{ $json.claude_model }}",
              "type": "string"
            },
            {
              "id": "keep-ollama",
              "name": "ollama_model",
              "value": "={{ $json.ollama_model || $json.model || 'llama3' }}",
              "type": "string"
            },
            {
              "id": "keep-mistral",
              "name": "mistral_model",
              "value": "={{ $json.mistral_model }}",
              "type": "string"
            },
            {
              "id": "4b68771f-f185-4c92-8c8b-01d51033f615",
              "name": "conversation_id",
              "value": "={{ $json.conversation_id }}",
              "type": "string"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "id": "8b1080d4-2a49-4dbb-8a50-965fbb931c5b",
      "name": "Context (original fields)",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -2528,
        992
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "no-rag",
              "leftValue": "={{ $json.rag }}",
              "rightValue": "true",
              "operator": {
                "type": "string",
                "operation": "notEquals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "184a135b-bf06-4f60-81c9-c4ace19ef308",
      "name": "without rag?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -2304,
        992
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://rag-backend:8082/query",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "x-api-key",
              "value": "={{ $('Context (original fields)').item.json.rag_api_key }}"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  query: $('Context (original fields)').item.json.prompt,\n  top_k: Number($('Context (original fields)').item.json.rag_top_k) || 5,\n  score_threshold: Number($('Context (original fields)').item.json.rag_score_threshold) || 0.45,\n  tags: Array.isArray($('Context (original fields)').item.json.rag_tags) ? $('Context (original fields)').item.json.rag_tags : []\n}) }}",
        "options": {
          "timeout": 300000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -2080,
        1088
      ],
      "id": "cce7d5e2-c1a9-4694-a41f-62edc256f8b8",
      "name": "RAG Query"
    },
    {
      "parameters": {
        "jsCode": "// Nimmt Input aus RAG- oder No-RAG-Pfad an und baut IMMER den finalen Prompt\nconst inData = $input.first().json || {};\nconst base   = $('Context (original fields)').first().json || {};\n\n// Quellen hübsch formatieren\nconst sources = Array.isArray(inData.sources) ? inData.sources : [];\nconst lines = sources.slice(0, 8).map((s, i) => {\n  const fn    = s?.meta?.filename || s?.filename || `Quelle ${i+1}`;\n  const score = (typeof s?.score === 'number') ? ` (score: ${s.score.toFixed(3)})` : '';\n  const snip  = s?.snippet ?? s?.content ?? s?.meta?.text ?? '';\n  const short = String(snip).replace(/\\s+/g, ' ').trim().slice(0, 600);\n  return `- ${fn}${score}: ${short}`;\n});\nconst contextBlock = lines.length ? `Kontext aus Daten:\\n${lines.join('\\n')}\\n\\n` : '';\n\n// Optional: Mini-Gedächtnis (falls du es schon eingebaut hast)\nconst mem = base.memory || { history: [], summary: '' };\nconst LAST_N = 8;\nconst histText = (Array.isArray(mem.history) ? mem.history : [])\n  .slice(-LAST_N)\n  .map(m => `${m.role === 'assistant' ? 'Assistent' : 'Nutzer'}: ${String(m.content||'').trim()}`)\n  .join('\\n');\n\nconst summaryBlock = mem.summary ? `Bisherige Zusammenfassung:\\n${mem.summary}\\n\\n` : '';\nconst historyBlock = histText ? `Letzte Nachrichten:\\n${histText}\\n\\n` : '';\n\nconst systemBlock  = (base.system && String(base.system).trim()) ? String(base.system).trim() + '\\n\\n' : '';\nconst userPrompt   = String(base.prompt ?? '').trim();\n\nconst augmented = `${systemBlock}${summaryBlock}${historyBlock}${contextBlock}Frage: ${userPrompt}`;\n\nconst modelOllama = base.ollama_model || base.model || 'llama3';\nconst temperature = typeof base.temperature === 'number' ? base.temperature : 0.7;\nconst top_p       = typeof base.top_p === 'number' ? base.top_p : 0.9;\nconst num_predict = typeof base.num_predict === 'number' ? base.num_predict : 600;\n\nreturn {\n  prompt: augmented,\n  system: base.system || '',\n  model: base.model,\n  ollama_model: modelOllama,\n  hf_model: base.hf_model,\n  openai_model: base.openai_model,\n  claude_model: base.claude_model,\n  mistral_model: base.mistral_model,\n  temperature, top_p, num_predict,\n  augmented_prompt: augmented,\n  sources,\n  used_tags: Array.isArray(inData.used_tags) ? inData.used_tags : []\n};\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1856,
        992
      ],
      "id": "92948afd-8f16-4001-bdd7-5c892bae1cff",
      "name": "Build Augmented Prompt"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-groq",
              "leftValue": "={{ $json.model }}",
              "rightValue": "groq",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "0e1f374e-62c9-472d-ad93-91a0f580cddc",
      "name": "Is groq?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -1632,
        992
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-openrouter",
              "leftValue": "={{ $json.model }}",
              "rightValue": "openrouter",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "e0f282f3-5e5a-4fd7-b50e-fcd34e1afa44",
      "name": "Is openrouter?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -1408,
        1184
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-mistralapi",
              "leftValue": "={{ $json.model }}",
              "rightValue": "mistralapi",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "5f934a9e-c3dc-4e6c-942f-f3f47c0d98cb",
      "name": "Is mistralAPI?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -1184,
        1328
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-openai",
              "leftValue": "={{ $json.model }}",
              "rightValue": "openai",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "c449e0d3-e93b-44e1-8872-0c65a9cd1514",
      "name": "Is OpenAI?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -960,
        1424
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-anthropic",
              "leftValue": "={{ $json.model }}",
              "rightValue": "anthropic",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "6a5f9f1c-c461-465f-a163-5104e9360877",
      "name": "Is Anthropic?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -736,
        1520
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-hf",
              "leftValue": "={{ $json.model }}",
              "rightValue": "huggingface",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "ed1b8088-6f90-429b-a856-a256fa53a979",
      "name": "Is HuggingFace?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -512,
        1616
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "is-mistral",
              "leftValue": "={{ $json.model }}",
              "rightValue": "mistral",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "7fafad6f-a9db-46d0-93a6-ab37e8ea12b8",
      "name": "Is Mistral?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        -288,
        1712
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: $json.openai_model,\n  messages: [\n    ...(($('Context (original fields)').first().json.system || '').trim() ? [{ role: 'system', content: $('Context (original fields)').first().json.system }] : []),\n    { role: 'user', content: $json.prompt }\n  ],\n  max_tokens: 1000,\n  temperature: 0.7\n}) }}",
        "options": {}
      },
      "id": "3c207e51-dde6-418f-85dc-e15406beb39c",
      "name": "Call OpenAI",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        0,
        1040
      ],
      "credentials": {
        "openAiApi": {
          "id": "xpFTPLasPN9qcrAU",
          "name": "OpenAi account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "anthropicApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: $json.claude_model,\n  max_tokens: 1000,\n  messages: [{ role: 'user', content: $json.prompt }],\n  ...((($('Context (original fields)').first().json.system || '').trim()) ? { system: $('Context (original fields)').first().json.system } : {})\n}) }}",
        "options": {}
      },
      "id": "65d32fc6-6502-481a-bb90-473b65537bbd",
      "name": "Call Claude",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        0,
        1232
      ],
      "credentials": {
        "anthropicApi": {
          "id": "NwPymGLQdk29P5fi",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api-inference.huggingface.co/models/{{ $json.hf_model }}",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "huggingFaceApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  inputs: (($('Context (original fields)').first().json.system || '').trim()) ? ($('Context (original fields)').first().json.system + '\\n\\n' + $json.prompt) : $json.prompt,\n  parameters: { max_length: 500, temperature: 0.7, do_sample: true, return_full_text: false }\n}) }}",
        "options": {}
      },
      "id": "f75139c9-5bae-481d-8ba7-4d5817a582f5",
      "name": "Call Hugging Face",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        0,
        1424
      ],
      "credentials": {
        "huggingFaceApi": {
          "id": "QO87qgUFRrbiQqXv",
          "name": "HuggingFaceApi account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.mistral.ai/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "mistralCloudApi",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: $json.mistral_model,\n  messages: [\n    { role: 'system', content: ($('Context (original fields)').first().json.system || 'Du bist ein hilfsbereiter Assistent.') },\n    { role: 'user', content: $json.prompt }\n  ],\n  max_tokens: 200,\n  temperature: 0.7\n}) }}",
        "options": {}
      },
      "id": "11f977f2-6462-4403-8217-ce8e303a2611",
      "name": "Call mistralAPI",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        0,
        848
      ],
      "credentials": {
        "mistralCloudApi": {
          "id": "cp078sOI6OYLKqiI",
          "name": "Mistral Cloud API-key"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://ollama:11434/api/generate",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: ($json.ollama_model) ?? ($('Context (original fields)').item.json.ollama_model ?? $('Context (original fields)').item.json.model ?? 'llama3'),\n  prompt: ($json.prompt) ?? ($('Context (original fields)').item.json.prompt ?? ''),\n  stream: false,\n  options: {\n    temperature: (typeof $json.temperature === 'number') ? $json.temperature : 0.7,\n    top_p:       (typeof $json.top_p === 'number')       ? $json.top_p       : 0.9,\n    num_predict: (typeof $json.num_predict === 'number') ? $json.num_predict : 600\n  }\n}) }}",
        "options": {
          "timeout": 300000
        }
      },
      "id": "01d9ebe8-4a17-4d5c-af16-7084896800c0",
      "name": "Call Ollama",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        0,
        1616
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "http://ollama:11434/api/generate",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ ({\n  model: 'llama3',\n  prompt: (($('Context (original fields)').first().json.system || '').trim()) ? ($('Context (original fields)').first().json.system + '\\n\\n' + $json.prompt) : $json.prompt,\n  stream: false,\n  options: { temperature: 0.7, num_predict: 500 }\n}) }}",
        "options": {}
      },
      "id": "a499eaf2-357c-4f27-ae27-92850cd7015d",
      "name": "Call Llama (Default)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4,
      "position": [
        0,
        1808
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ (($('Context (original fields)').first().json.system || '').trim()) ? $('Context (original fields)').first().json.system + \"\\n\\n\" + $json.prompt : $json.prompt }}",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        -64,
        48
      ],
      "id": "aca2ce71-c3ba-4b61-aca4-4fe012c7a49d",
      "name": "Basic LLM Chain"
    },
    {
      "parameters": {
        "jsCode": "// Response Formatter (angepasst auf Subflow)\nconst requested = $('Context (original fields)').first().json || {};\nconst item = $input.first();\nlet data = item.json;\n\nfunction parseNdjsonString(s){try{const lines=String(s).trim().split('\\n').filter(Boolean);return lines.map(l=>JSON.parse(l));}catch{return null;}}\nfunction parseSseString(s){const out=[];for(const line of String(s).split('\\n')){const t=line.trim();if(!t||!t.toLowerCase().startsWith('data:'))continue;const p=t.slice(5).trim();if(!p||p==='[DONE]')continue;try{out.push(JSON.parse(p));}catch{}}return out.length?out:null;}\nfunction extractTextFromChunk(o){if(typeof o.response==='string')return o.response;const c=o.choices&&o.choices[0];if(c){if(c.delta&&typeof c.delta.content==='string')return c.delta.content;if(c.message&&typeof c.message.content==='string')return c.message.content;if(typeof c.text==='string')return c.text;if(Array.isArray(c.content))return c.content.map(x=>typeof x.text==='string'?x.text:'').join('');}\nif(typeof o.content==='string')return o.content; if(typeof o.output_text==='string')return o.output_text; if(typeof o.text==='string')return o.text; return '';}\n\nlet result, provider, actualModel, usage=null, raw=data;\nif(typeof data==='string'){raw={data};data={data};}\nif(data&&typeof data.data==='string'){\n  let chunks=parseNdjsonString(data.data);\n  if(chunks&&chunks.length){provider='Ollama';actualModel=(chunks.find(o=>o.done===true)?.model)||chunks[0]?.model||requested.ollama_model;result=chunks.map(extractTextFromChunk).filter(Boolean).join('').trim();raw={ndjson:chunks};}\n  else{chunks=parseSseString(data.data);if(chunks&&chunks.length){provider=(chunks.find(o=>o?.provider)?'OpenRouter':'Groq/OpenAI-like');actualModel=(chunks.find(o=>o?.model)?.model)||requested.model||requested.openai_model||requested.ollama_model;result=chunks.map(extractTextFromChunk).filter(Boolean).join('').trim();raw={sse:chunks};}}\n}\nif(!result){\n  if(data&&data.choices?.[0]?.message){result=data.choices[0].message.content;provider='OpenAI';actualModel=data.model||requested.openai_model;usage=data.usage||null;}\n  else if(data&&Array.isArray(data.content)&&data.content[0]){result=data.content[0].text||data.content[0].content;provider='Claude/Anthropic';actualModel=data.model||requested.claude_model;}\n  else if(Array.isArray(data)&&data[0]?.generated_text){result=data[0].generated_text;provider='Hugging Face';actualModel=requested.hf_model;}\n  else if(data&&data.generated_text){result=data.generated_text;provider='Hugging Face';actualModel=requested.hf_model;}\n  else if(data&&typeof data.response==='string'){result=data.response;provider='Ollama';actualModel=data.model||requested.ollama_model;}\n  else if(data&&data.text){result=data.text;provider='OpenRouter';actualModel=requested.model||requested.openai_model||requested.ollama_model;}\n  else if(data&&data.error){result=`Error: ${data.error.message||JSON.stringify(data.error)}`;provider='Error';actualModel='N/A';}\n  else {result=`Unexpected response format: ${JSON.stringify(data)}`;provider='Unknown';actualModel='N/A';}\n}\n\nlet sources=[], used_tags=[]; try{const rag=$('Build Augmented Prompt').first().json||{}; if(Array.isArray(rag.sources))sources=rag.sources; if(Array.isArray(rag.used_tags))used_tags=rag.used_tags;}catch{}\n\nreturn {\n  result:(result||'').trim(),\n  status:(provider==='Error')?'error':'success',\n  provider,\n  model_requested: requested.model,\n  model_used: actualModel,\n  timestamp: new Date().toISOString(),\n  usage,\n  raw_response: raw,\n  sources,\n  used_tags,\n  original_prompt: $('Context (original fields)').first().json.prompt,\n  conversation_id: $('Context (original fields)').first().json.conversation_id\n};"
      },
      "id": "a7bb59ad-d4fe-4511-a2b2-ae2541b7f6f1",
      "name": "Format Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        288,
        1136
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ (($('Context (original fields)').first().json.system || '').trim()) ? $('Context (original fields)').first().json.system + \"\\n\\n\" + $json.prompt : $json.prompt }}",
        "needsFallback": true,
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        -64,
        448
      ],
      "id": "ee05aa01-89ad-4ac2-8cb9-b2584904add7",
      "name": "Basic LLM Chain1"
    },
    {
      "parameters": {
        "model": "moonshotai/kimi-k2-instruct",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        -64,
        272
      ],
      "id": "210d34b9-4acb-4814-865f-6aec29359e9c",
      "name": "Moonshot/Kimi",
      "credentials": {
        "groqApi": {
          "id": "mhumLW1ZXnpB1MfM",
          "name": "Groq account"
        }
      }
    },
    {
      "parameters": {
        "model": "deepseek-r1-distill-llama-70b",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        80,
        272
      ],
      "id": "ac257db7-1e88-4c4e-aa04-05d5f605671a",
      "name": "Deepseek",
      "credentials": {
        "groqApi": {
          "id": "mhumLW1ZXnpB1MfM",
          "name": "Groq account"
        }
      }
    },
    {
      "parameters": {
        "model": "openai/gpt-oss-120b",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        -64,
        672
      ],
      "id": "e7e38820-4267-4d5e-b434-a7b33a1dedbc",
      "name": "GPT-OSS",
      "credentials": {
        "openRouterApi": {
          "id": "h5qqZ7le0CZSkkCh",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "model": "qwen/qwen3-32b",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatGroq",
      "typeVersion": 1,
      "position": [
        80,
        672
      ],
      "id": "51e56f88-b840-4fdb-baae-d35c5942b0da",
      "name": "qwen3",
      "credentials": {
        "groqApi": {
          "id": "mhumLW1ZXnpB1MfM",
          "name": "Groq account"
        }
      }
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "c6cdfd6f-7e91-493c-b4ab-a565d824584c",
              "name": "sources",
              "value": "",
              "type": "string"
            },
            {
              "id": "f3453492-81cc-4ecf-bc2e-66ca20087ff3",
              "name": "used_tags",
              "value": "",
              "type": "string"
            }
          ]
        },
        "includeOtherFields": true,
        "options": {}
      },
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        -2080,
        896
      ],
      "id": "b082cb25-3b3b-44d4-8ac6-6bad916bcbcb",
      "name": "No RAG Context"
    }
  ],
  "pinData": {},
  "connections": {
    "Execute Workflow Trigger": {
      "main": [
        [
          {
            "node": "Context (original fields)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Context (original fields)": {
      "main": [
        [
          {
            "node": "without rag?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "without rag?": {
      "main": [
        [
          {
            "node": "No RAG Context",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "RAG Query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "RAG Query": {
      "main": [
        [
          {
            "node": "Build Augmented Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Augmented Prompt": {
      "main": [
        [
          {
            "node": "Is groq?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is groq?": {
      "main": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is openrouter?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is openrouter?": {
      "main": [
        [
          {
            "node": "Basic LLM Chain1",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is mistralAPI?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is mistralAPI?": {
      "main": [
        [
          {
            "node": "Call mistralAPI",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is OpenAI?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is OpenAI?": {
      "main": [
        [
          {
            "node": "Call OpenAI",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is Anthropic?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is Anthropic?": {
      "main": [
        [
          {
            "node": "Call Claude",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is HuggingFace?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is HuggingFace?": {
      "main": [
        [
          {
            "node": "Call Hugging Face",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Is Mistral?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Is Mistral?": {
      "main": [
        [
          {
            "node": "Call Ollama",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Call Llama (Default)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call OpenAI": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Claude": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Hugging Face": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call mistralAPI": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Ollama": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Call Llama (Default)": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Basic LLM Chain1": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Moonshot/Kimi": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Deepseek": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "GPT-OSS": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain1",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "qwen3": {
      "ai_languageModel": [
        [
          {
            "node": "Basic LLM Chain1",
            "type": "ai_languageModel",
            "index": 1
          }
        ]
      ]
    },
    "No RAG Context": {
      "main": [
        [
          {
            "node": "Build Augmented Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "c9999e81-c2b9-4974-a743-8ad865b0adbc",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "5e9f1d1029083353f9423560cb0b3070390ad03855815e064cf1d2e50cd094b4"
  },
  "id": "LaPkdCUyheq3rQnf",
  "tags": [
    {
      "createdAt": "2025-08-15T08:00:40.082Z",
      "updatedAt": "2025-08-15T08:00:40.082Z",
      "id": "MIGc52SFD5ylOxsf",
      "name": "Subflow"
    }
  ]
}